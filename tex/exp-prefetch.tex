\subsection{\zrdnew{Prefetching Performance Analysis}}
\label{exp:prefetch}
\begin{figure}
	\centering
	\includegraphics[width=3.3in, height=1in]{acc_cov.pdf}
%	\vspace{-0.1in}
	\caption{\zrdnew{The prefetch accuracy of each method.}}
	\label{fig:cov_acc}
	\vspace{-0.1in}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=3.3in, height=1in]{his_ours_io.pdf}
%	\vspace{-0.1in}
	\caption{\zrdnew{The prefix KVs loading time on the inference critical path of each method.}}
	\label{fig:his_ours_io}
	\vspace{-0.1in}
\end{figure}
\zrdnew{
HyperInfer employs the \technew{} mechanism described in \cref{sec:technew} 
(denoted as \textit{LAYER-WISE}) to prefetch important KVs for the next layer. 
We compare it against a naive history-based baseline (denoted as \textit{HISTORY}), 
which prefetches KVs solely based on their global historical usefulness, 
independent of the current request, as described in \S\ref{motiv}.
We evaluate the two methods along two dimensions:  
(1) \textbf{Prefetch accuracy}, defined as the fraction of prefetched KVs that actually appear in the next layerâ€™s important-KV set; and  
(2) \textbf{Critical-path I/O time}, which measures the amount of KV loading that 
remains exposed on the inference critical path.
These metrics collectively show how precisely each method selects the KVs 
that matter for the next layer and how effectively it hides I/O latency.
}

\zrdnew{Figure~\ref{fig:cov_acc} compares the prefetch accuracy of our method with the history-based method. 
Our approach consistently achieves higher accuracy across models and datasets, 
with an average improvement of $x\%$. 
This improvement indicates that \technew{} is significantly more effective 
at predicting which KVs will be important in the next layer.	
Benefiting from the higher accuracy, the amount of KV loading that remains on the 
critical path is also substantially reduced. 
As shown in Figure~\ref{fig:his_ours_io}, compared to the history-based method, 
our approach reduces critical-path I/O time by $x\times$ to $x\times$, 
demonstrating its superior ability to hide I/O latency and shorten TTFT.}
% LaTeX template for Artifact Evaluation V20201122
%
% Prepared by 
% * Grigori Fursin (cTuning foundation, France) 2014-2020
% * Bruce Childers (University of Pittsburgh, USA) 2014
%
% See examples of this Artifact Appendix in
%  * SC'17 paper: https://dl.acm.org/citation.cfm?id=3126948
%  * CGO'17 paper: https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf
%  * ACM ReQuEST-ASPLOS'18 paper: https://dl.acm.org/citation.cfm?doid=3229762.3229763
%
% (C)opyright 2014-2020
%
% CC BY 4.0 license
%

% \documentclass{sigplanconf}

% \usepackage{hyperref}
% \hypersetup{
%     colorlinks = true,
%     linkcolor=blue,
%     filecolor=blue,      
%     urlcolor=blue,
%     citecolor=cyan,
% }

% \begin{document}

% \special{papersize=8.5in,11in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove above part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\section{Artifact Appendix}
\label{sec:ae}

\subsection{Abstract}

The artifact provides the core algorithm implementation code and testing scripts for the XYZ system. It optimizes the existing network protocol stack and can be seamlessly integrated with existing network applications through simple configuration.

\subsection{Scope}

The artifact helps to gain a deeper understanding of our design concepts and implementation details, including those not mentioned in the paper due to space limitations. It allows for the reproduction of the experimental results presented in the paper and provides examples for developers to integrate the XYZ system into their own network applications.

\subsection{Contents}

The implementation code in the artifact consists of two main parts: the userspace shared library libxyz (xyzLib) and the optimized network protocol stack module. Additionally, the artifact includes testing scripts and third-party applications, such as NetBench and FlowSim.

\subsection{Hosting}

The artifact is available at https://github.com/xxx. The main branch contains the latest content.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Abstract}
%
%% {\em Obligatory}
%The artifact contains the prototype implementations of ChunkGraph, 
%We also provide the implementations of the comparison baselines, 
%i.e., Ligra-mmap and Blaze. 
%All implementations are based on the Ligra framework. 
%This artifact should enable others to reproduce a subset of 
%our results and conduct their own studies. 
%% Ligra 介绍+链接
%
%\subsection{Artifact check-list (meta-information)}
%
%% {\em Obligatory. Use just a few informal keywords in all fields applicable to your artifacts
%% and remove the rest. This information is needed to find appropriate reviewers and gradually 
%% unify artifact meta information in Digital Libraries.}
%
%{\small
%\begin{itemize}
%  % \item {\bf Algorithm: }
%  \item {\bf Program: } Linux kernel of 5.4.0, ChunkGraph, Ligra, Blaze. 
%  \item {\bf Compilation: } GCC 10.5.0 with OpenMP.
%  % \item {\bf Transformations: }
%  % \item {\bf Binary: }
%  % \item {\bf Model: }
%  \item {\bf Data set: } Four real-world graphs Twitter, Friendster, UKdomain and Yahoo Web, 
%  as well as two synthetic Kronecker graphs, i.e., Kron-29 and Kron-30, 
%  which are generated by graph500 generator.
%  \item {\bf Run-time environment: } Ubuntu 20.04.6.
%  \item {\bf Hardware: } A server with two processors 
%  each with 24 physical cores with hyper-threading enabled (48 logical cores), 
%  with 8 $\times$ 16GB (128 GB) DRAM and two 4 PCIe-attached Intel P5520 NVMe SSDs. %(3.84 TB). 
%
%  % \item {\bf Run-time state: } Managed by tooling automatically.
%  \item {\bf Execution: } Automated by shell scripts.
%  \item {\bf Metrics: } Graph analytic performance, I/O and computation overhead. 
%  \item {\bf Output: } The key results would be recorded to the directory {\em results/}. 
%  \item {\bf Experiments: } Graph analytic performance (Fig.8), 
%  I/O overhead for Yahoo/Kron30 datasets (Fig.9), 
%  and computation overhead for Yahoo/Kron30 datasets (Fig.10).
%  \item {\bf How much disk space required (approximately)?: } 5 TB.
%  % \item {\bf How much time is needed to prepare workflow (approximately)?: } \red{48} hours for downloading and preprocessing all graph datasets. % in our machine. 
%  \item {\bf How much time is needed to complete experiments (approximately)?: } 4 hours. 
%  \item {\bf Publicly available?: } Yes.
%  % \item {\bf Code licenses (if publicly available)?: } {{todo}}
%  % \item {\bf Data licenses (if publicly available)?: }
%  \item {\bf Workflow framework used?: } No, but scripts are provided to automate the measurements. 
%  % \item {\bf Archived (provide DOI)?: }  
%  \item {\bf Archived: }  
%  \href{https://zenodo.org/doi/10.5281/zenodo.11181584}{{zenodo.org/doi/10.5281/zenodo.11181584}}
%\end{itemize}
%}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Description}
%
%\subsubsection{How to access}
%
%% {\em Obligatory}
%The source code and scripts are host on Zenodo,
%\url{https://zenodo.org/doi/10.5281/zenodo.11181584}.
%
%\subsubsection{Hardware dependencies}
%This artifact runs on a server with two processors, 
%each with 24 physical cores with hyper-threading enabled (48 logical cores). 
%For memory, it equips with 8 x 16 GB (128 GB) DRAM. 
%For storage, it equips with two 4 PCIe-attached Intel P5520 NVMe SSDs. %(3.84 TB).
%
%\subsubsection{Software dependencies}
%This artifact runs on Ubuntu 20.04.6 LTS with Linux kernel of 5.4.0, 
%and we use GCC 10.5.0 with -O3 optimization for evaluation. 
%Other dependencies such as NUMA and Zlib libraries may also be necessary.
%% OpenMP
%
%\subsubsection{Datasets}
%We use four real-world graphs Twitter, Friendster, UKdomain and Yahoo Web, 
%as well as two synthetic Kronecker graphs, i.e., Kron-29 and Kron-30, 
%which are generated by graph500 generator, for our evaluation. 
%Datasets download links: 
%
%\begin{itemize}
%  \item {\bf Twitter:} \url{https://anlab-kaist.github.io/traces/WWW2010}
%  \item {\bf Friendster:} \url{ http://konect.uni-koblenz.de/networks/friendster}
%  \item {\bf UKdomain:} \url{ http://konect.cc/networks/dimacs10-uk-
%  2007-05}
%  \item {\bf Yahoo Web:} \url{ http://webscope.sandbox.yahoo.com}
%  % \item {\bf Graph500 generator:} \url{ https://github.com/rwang067/graph500-3.0}
%\end{itemize}
%
%Graph500 generator link and Kronecker graph generation commands: 
%\begin{itemize}
%  \item {\bf Generator link:} \url{ https://github.com/rwang067/graph500-3.0}
%  \item {\bf Make genetator:} cd graph500-3.0/src \&\& make graph500\_reference\_bfs
%  \item {\bf Generate Kron29:} ./graph500\_reference\_bfs 29 16 kron29.txt
%  \item {\bf Generate Kron30:} ./graph500\_reference\_bfs 30 16 kron30.txt
%\end{itemize}
%
%% \subsubsection{Models}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Installation}
%
%% {\em Obligatory}
%Users need to download the source code and scripts 
%from Zenodo to the server. 
%The following is the directory structure of the source code, scripts, and instructions:
%
%\begin{itemize}
%  \item {\bf README.md:} This file contains a detailed step-by-step "Getting Started Instructions" guide, and "Detailed Instructions" for running the experiments. 
%  \item {\bf src/:} This directory contains the source code of ChunkGraph and Ligra-mmap. 
%  \item {\bf CSRGraph/:} This directory contains the source code of Chunk Layout Optimization of ChunkGraph. 
%  \item {\bf apps/:} This directory contains contains the graph query algorithms for ChunkGraph and Ligra-mmap. 
%  \item {\bf blaze/:} This directory contains the source code of Blaze. 
%  \item {\bf scripts/:} This directory contains the scripts for running the experiments.
%  \item {\bf preprocess/:} This directory contains the scripts for converting the input data from text format to csr-based binary and chunk-format binary. 
%\end{itemize}
%
%After downloading the source code and scripts, users need to compile ChunkGraph and prepare data sets. 
%To evaluate the performance of comparison systems, users need to compile Blaze and Ligra-mmap. 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Experiment workflow}
%The suggested workflow is organized in scripts/, which includes all the scripts for running the experiments.
%Users can run the experiments by `bash scripts/run.sh`. 
%The running progress and the expected completing time of each experiment would be printed to the file `scripts/progress.txt` automatically.
%Note that you may have to change some arguments according to your environment, 
%such as dataset path, taskset-cpu list, and the number of threads.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Evaluation and expected results}
%% {\em Obligatory}
%The evaluation results would be generated to the directory `results/`.
%Users can reproduce the results in Figure 8, Figure 9, and Figure 10, 
%which should roughly match the respective figures from the paper. 
%
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Experiment customization}
%
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Notes}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Methodology}
%
%Submission, reviewing and badging methodology:
%
%% \small
%\begin{itemize}
%  \item \url{https://www.acm.org/publications/policies/artifact-review-badging}
%  \item \url{http://cTuning.org/ae/submission-20201122.html}
%  \item \url{http://cTuning.org/ae/reviewing-20201122.html}
%\end{itemize}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% When adding this appendix to your paper, 
%% please remove below part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%% \end{document}